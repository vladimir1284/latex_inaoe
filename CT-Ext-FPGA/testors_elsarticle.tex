%%
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%

%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references
%% SP 2008/03/01
%%
%%
%%
%% $Id: elsarticle-template-harv.tex 4 2009-10-24 08:22:58Z rishi $
%%
%%
%%\documentclass[preprint,authoryear,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
\documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,authoryear,1p,times]{elsarticle}
%% \documentclass[final,authoryear,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,authoryear,3p,times]{elsarticle}
%% \documentclass[final,authoryear,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,authoryear,5p,times]{elsarticle}
%% \documentclass[final,authoryear,5p,times,twocolumn]{elsarticle}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
\usepackage{graphics}
\usepackage{longtable}
%% or use the graphicx package for more complicated commands
%% \usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}
\usepackage{colortbl}

% For psudo code
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{setspace}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon (default)
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   authoryear - selects author-year citations (default)
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%   longnamesfirst  -  makes first citation full author list
%%
%% \biboptions{longnamesfirst,comma}

% \biboptions{}

\journal{Expert Systems with Applications}

\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{A New Fast Hardware Software Platform for Computing Irreducible Testors}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}


\address{Computer Science Department}
\address{National Institute for Astrophysics, Optics and Electronics}
\address{Sta. Ma. Tonanzintla, Puebla, 72840, Mexico}

\begin{abstract}
Feature selection is an important task in pattern recognition. Given a dataset described by a set of attributes, a minimum subset of attributes that preserves the ability to discern between objects from different classes is needed. The computation of this minimum subset is a problem whose space complexity grows
exponentially regarding the number of attributes. Testor Theory is a convenient way to solve this problem. A testor is defined as a subset of attributes that can discern between objects of different classes; and an irreducible testor is a minimal subset with this property. Although there are efficient algorithms for computing irreducible testors, hardware implementations of these algorithms can improve their performance; taking advantage of the inherent parallelism in the evaluation of testor candidates. In this paper, a new fast hardware software platform for computing irreducible testors is presented. Results from a prototype implementation showing the advantages of the proposed platform, are presented and discussed.

\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Feature Selection \sep Testor Theory \sep Hardware Architecture \sep
FPGA
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

% \linenumbers

%% main text
\section{Introduction}
\label{sect:1}

%Reconfigurable computing based on the combination of conventional
%microprocessors and field programmable gate arrays (FPGAs), has
%become increasingly popular for implementing special-purpose
%hardware to accelerate complex tasks. Usually an FPGA-based
%implementation is embedded in a PC or workstation, which drives its
%activity and manages the results. 

Feature selection for supervised classification consists in identifying those attributes that 
provide relevant information for the classification process. This procedure does not only reduce the 
computational cost of the classification process by eliminating superfluous information, but in some cases 
it could even provide better classification accuracy. 
%Several algorithms have been proposed to overcome 
%the exponential complexity intrinsic to feature selection, however, most of them were restricted to 
%numeric attributes \citep{R3,R4}. 
Testor Theory can be used for feature selection as shown in~\citep{R27,R5}. A testor is defined as a subset of attributes that can discern objects from different classes. An irreducible testor is a subset of features such that every attribute is indispensable for satisfying the testor condition. Finding all irreducible testors has been proven as an NP-hard problem~\citep{R40}.

Recently, there is an increasing popularity of architectures based on Field Programmable Gate-Array (FPGA) 
for solving complex computational problems. Several hardware-software platforms based on this technology have 
been reported \citep{R29,R30}. 
In these platforms, the software component handles those tasks less suited for hardware implementation, 
and it is also responsible of configuring the FPGA, as well as handling communication with the hardware component. 
The hardware component, on the other hand, performs those operations with a high parallelism degree.

In spite of advances in the theoretical aspects of computing
irreducible testors \citep{R5,R8,R9}, there are 
no hardware implementations reported aside from \citep{R10,R11,R21}.
In the first work, an FPGA-based brute force approach for computing testors was proposed
\citep{R10}. This first approach did not take advantage of dataset characteristics to reduce the number 
of candidates to be tested; thus all $2^n$ combinations of $n$ features have to be tested. 
Then, in \citep{R11} a hardware architecture of the BT algorithm for computing irreducible testors was implemented. 
This algorithm uses a candidate pruning process for avoiding many unnecessary candidate evaluation, 
reducing the number of verifications of the irreducible testor condition. 
These two previous works computed a set of testors on the FPGA device whilst irreducible condition 
was evaluated afterwards by the software component in the hosting PC. 
Thus \cite{R21} proposed a hardware-software platform for computing irreducible testors that 
implemented the BT algorithm, as in \citep{R11}, but it also included a new module that eliminates most of 
the non irreducible testors before transferring them to a host software application for final filtering. 
One disadvantage of these approaches is the huge amount of data that must be transferred to the PC.  
For this reason, in this paper, we develop an efficient hardware-software platform for computing irreducible
testors for feature selection %\citep{R2,R3,R17,R18,R19} 
using the CT-EXT algorithm proposed in~\citep{R22} which computes only typical testors, 
reducing the amount of data that must be transferred to the PC. Additionally, CT-EXT has proven being, 
in most cases, more efficient in finding irreducible testors than BT~\citep{R22, R23}.

The intensive computational requirements due to the exponential
complexity, regarding the number of attributes, of the CT-EXT algorithm,
can be met by a combination of technological improvements and efficient hardware architectures based on 
parallel computational models. 
%Further optimizations such as incremental
%processing and the use of multiple processing elements are also
%possible as will be shown later in this paper.

The rest of this paper is structured as follows. Section~\ref{sect:2} introduces the basic concepts of 
Testor Theory and the CT-EXT algorithm. Section~\ref{sect:3} introduces the proposed platform.  
Evaluation of the proposed platform and a discussion of the experimental results are 
presented in section~\ref{sect:6}. Finally, section~\ref{sect:8} shows our conclusions and some directions 
for future work.

\section{Basic concepts}
\label{sect:2}

In pattern recognition, feature selection is a very important task for supervised classification. In the logical
 combinatorial approach to pattern recognition \citep{R5}, 
%TODO include J. Ruiz-Shulcloper, M.A. Abidi. Logical Combinatorial Pattern Recognition: A Review // In S.G. Pandalai. Recent Research Developments in Pattern Recognition. 2002. P 133-76. 
a useful
way to deal with this problem is through Testor Theory. The concept of testor for pattern recognition was
introduced by \cite{R12}. They defined a testor as a subset of features that allows
differentiating objects from different classes. Testors are quite useful, especially when object descriptions
contain both numeric and non-numeric features, and maybe they are incomplete (mixed incomplete data)
\citep{R5}. This concept has been developed in different contexts \citep{R1}. From an 
algorithmic point of view, Testor Theory has shown a continuous development from its origins to the present 
\citep{R31,R13,R23}.

Let $TM$ be a training matrix with $k$ objects described through $n$
features of any type $\{x_{1},\ldots,x_{n}\}$ and grouped in $r$
classes. Let $DM$ be a Boolean dissimilarity matrix (0 = similar, 1 =
dissimilar), obtained from feature by feature comparisons of every
pair of objects from $TM$ belonging to different classes. $DM$ has
$m$ rows and $n$ columns, where usually $m>>k$.

Let $T$ be a subset of attributes. Testors and irreducible testors are formally defined as follows:

\begin{definition} \label{def1}
$T$ is a testor if and only if when all
features (columns) are eliminated from $DM$, except those from $T$, there is
not any row of $DM$ with only 0's. $T$ is an irreducible testor if none of its proper subsets is a testor.
\end{definition}

In defintion \ref{def1}, if there is not any row of $DM$ with only
0's it means that there is not a pair of objects from different
classes that are similar on all the features of $T$, that is, a
testor $T$ allows differentiating objects from different
classes. From definition~\ref{def1}, if $T$ is a testor then, any superset of $T$ is a testor too.

The number of rows in $DM$ could be too large, therefore a strategy to reduce this matrix, without losing
relevant information for computing irreducible testors, is eliminating redundant rows \citep{R1}.

%% DEFINICION 
\begin{definition}
Let $f=[f_1, f_2, \dots , f_n]$ and $f'=[f'_1, {f'}_2, \dots , {f'}_n]$ be two rows of $DM$, $f$ 
is a sub-row of $f^{'}$ if for each column $j=1,2,\dots ,n$;  $f_{j} \le f'_{j}$ and for at least one index, the 
inequality is strict.
\end{definition}

%% DEFINICION 
\begin{definition}
A row $f$ of $DM$ is a basic row if no row of the matrix $DM$ is a sub-row of $f$. 
\end{definition}

%% DEFINICION 
\begin{definition}
The basic matrix of $DM$, denoted as $BM$, is the sub-matrix of $DM$ formed only by the basic rows (without 
repetitions).

\end{definition}

Let $TT(DM)$ and $TT(BM)$ be the sets of all irreducible testors of $DM$ and $BM$ respectively, it is 
relatively easy to prove that $TT(DM)=TT(BM)$, see \citep{R32}; i.e., we can conclude that usually $DM$ 
contains redundant information. In addition, the construction of $BM$ from $DM$ is a very fast process, 
then we work over $BM$.

The CT-EXT algorithm has the following theoretical bases.
\begin{definition} \label{def21} Let $f_i$ be a row of BM, $f_i$ is a zero row of $S \subseteq R$, and we denote it as ${f_i}^0 (S)$, if $\forall x_p \in S$, $f_i [p] = BM [i, p] = 0$. We denote as $\Sigma_S f^0$  the amount of zero rows of S.
\end{definition}
\begin{definition} \label{def22} In terms of BM, a testor $T \subseteq R$ is a feature set such that there
are no zero rows of T in BM. 
\end{definition}
\begin{definition} \label{def23} Let $f_i$ be a row of BM, $f_i$ is a typical row of $S \subseteq R$ regarding $x_q$, being $x_q \in S$, and we denote it by ${f_i}^1 (S,q)$ if $f_i [q] = BM [i, q] = 1$, and $\forall x_p \in S$, $x_p \neq x_q$ , $f_i [p] = BM [i, p] =~0$.
\end{definition}

\begin{definition} \label{def24} In terms of BM, $T \subseteq R$ is an irreducible testor if T is a testor and
$\forall x_j \in T, \exists {f_i}^1 (T, j)$.
\end{definition}

This means that for each feature in an irreducible testor, there exists a row in 
the sub matrix of $BM$ associated to $T$, having a 1 in the position corresponding
to that feature, and 0 in all remaining positions (if any column of $T$ is eliminated, 
at least one zero row will appear, and the testor property would not be fulfilled). 

\begin{definition} \label{def25} Given $T \subseteq R$ and $x_j \in R$ such that $x_j \notin T$. 
%We denote as $\sum_T f^0$ the amount of zero rows of T. 
We say that $x_j$ contributes to T if, and only if, $\sum_{T\cup\{x_j\}} f^0 < \sum_T f^0$.
\end{definition}
This definition indicates that a feature contributes to a feature subset $T$
if for at least one zero row in $BM$, considering only $T$, the new feature has a 1 in 
this row. So, adding this feature to $T$, there are less
zero rows than the amount of zero rows for $T$.

It is easy to see that $\sum_T f^0 \geq \sum_{T\cup\{x_j\}} f^0$. If we
increase the feature subset, either the zero rows are maintained, and in this
case the column added does not contribute to the combination, or the number of zero rows decreases.

Propositions~\ref{prop1} and~\ref{prop2} are important conclusions for CT-EXT which were introduced and 
proved in \citep{R22}.

\begin{proposition}\label{prop1} Given $T \subseteq R$ and  $x_j \in R$ such that $x_j \notin T$. If $x_j$ does not contribute to T, then $T\cup\{x_j\}$ cannot be a subset of any irreducible testor.
\end{proposition}

%\textit{Proof}. Let $T \subseteq R$ and $x_j \in R$, such that $x_j$ does not contribute to T. Suppose
%that $T' = T\cup\{x_j \cup Z\}$ is a typical testor. Then, according to definition \ref{def24}, there
%exists for $x_j$ at least a typical row in $BM$. Then, $f_i [j] = BM [i, j] = 1$, and
%$\forall x_p \in T'$ , $x_p \neq x_j$ , $f_i [p] = BM [i, p] = 0$. Thus, we have that $f_i$ is a zero row
%of $T \cup Z$ and therefore, it is also a zero row of $T$. So, $\sum_{T\cup\{x_j\}} f^0 < \sum_T f^0$ and we obtain that
%$x_j$ contributes to $T$, which contradicts the formulated hypothesis and then, we
%have that there are no typical testors that include $T\cup\{x_j\}$.

\begin{proposition}\label{prop2} Given $T \subseteq R$ and $Z \subseteq R$ such that $Z \cup T \neq T$. If T is a testor, 
then $T \cup Z$ is a testor too, but it is not an irreducible testor.
\end{proposition}

%\textit{Proof}. Being $T$ a testor, we have that $\sum_T f^0 = 0$, therefore, any feature $x_p \in Z$
%contributes to $T$. Since $T \cup Z$ is a superset of $T$, then $T \cup Z$ is a testor, but
%following proposition~\ref{prop1}, it can not generate any typical testor.
\subsection{CT-EXT algorithm}
Algorithm~\ref{ctext_algo} exposes the pseudo code for CT-EXT, a detailed explanation for 
this algorithm can be seen in~\citep{R22}. The function SortBM$(BM)$ sorts the basic matrix as follows.
Randomly select one of the rows of $BM$ with the fewest number of 1's. The selected row goes first and 
all columns in which it has a 1 are moved to the left.  

The function Evaluate$(BM,T)$ returns three values: $testor$, $irreducible$ and $zero\_rows$. $testor$ is TRUE if the set $T$ is a testor of $BM$ and FALSE otherwise. $irreducible$ is TRUE if the set $T$ is an irreducible testor and FALSE otherwise. $zero\_rows$ is the amount of zero rows of $T$. The function LastOne($T$) returns the 
position of the rightmost element in the set $T$.

\begin{algorithm}
	\begin{spacing}{1.0}
	\begin{small}	
	\caption{CT-EXT algorithm}\label{ctext_algo}
	\begin{algorithmic}[1]	
		%\Procedure{CT-EXT}{}
		\State \textbf{Input: } $BM$ - basic matrix with $m$ rows and $n$ columns.
		\State \textbf{Output: } $TT$ - set of irreducible testors.
			
			\State $TT \gets \{\}$
			\State $j \gets 0$ \Comment{first feature from $BM$ to be analyzed}
			\State $BM \gets$ SortBM$(BM)$
			
			\While{$BM[0,j] \neq 0$}\label{row1condition}
				\State $T \gets \{X_j\}$ \Comment{current feature subset}
				\State $testor, irreducible, zero\_rows \gets$ Evaluate$(BM,T)$
				\If{$testor=TRUE$}
					\If{$irreducible=TRUE$} \Comment{$T$ is an irreducible testor}
						\State $TT \gets TT \cup T$
					\EndIf
				\Else
					\State $i \gets j+1$
					\While{$i < n$}
						\State $T \gets T \cup \{X_i\}$
						\State $zero\_rows\_last \gets zero\_rows$
						\State $testor, irreducible, zero\_rows \gets$ Evaluate$(BM,T)$
						\If{$zero\_rows = zero\_rows\_last$} 
							\State $T \gets T \setminus \{X_i\}$ \Comment{attribute $X_i$ does not contributes}
						\Else
							\If{$testor=TRUE$}
								\If{$irreducible=TRUE$}
									\State $TT \gets TT \cup T$
								\EndIf
								\State $T \gets T \setminus \{X_i\}$
								\State $zero\_rows \gets zero\_rows\_last$
							\EndIf
						\EndIf
						\If{$i = n-1$}
							\State $k \gets$ LastOne($T$)
							\If{$k = i$}
								\State $T \gets T \setminus \{X_k\}$
								\State $k \gets$ LastOne($T$)
							\EndIf
							\If{$k \neq j$}
								\State $T \gets T \setminus \{X_k\}$
								\State $testor, irreducible, zero\_rows \gets$ Evaluate$(BM,T)$
								\State $i \gets k+1$
							\Else
								\State $i \gets i+1$
							\EndIf
						\Else
							\State $i \gets i+1$
						\EndIf
					\EndWhile
				\EndIf
				\State $j \gets j+1$
			\EndWhile
		%\EndProcedure
	\end{algorithmic}
	\end{small}
	\end{spacing}
\end{algorithm}
%\begin{enumerate}
%\item Select a row of $BM$ that has fewest 1's. The selected row goes first and all columns in which it has a 1 
%are moved to the left. The order of the columns into each group (with the same value in the first column, 
%1 or 0) is irrelevant.
%%The row with less quantity of 1's, is set as the first row of $BM$. The columns of $BM$ are ordered, from left to right, each having a 1 in the first row and each subsequent column having a 0 in the first row of $BM$. The order of the columns is irrelevant in a $BM$ matrix.
%
%\item Let the sets $TT = \{~\}$ (the typical testors set) and $T = \{~\}$  (the current feature combination) be initialized as empty sets; $j = 1$ (first feature of $BM$ to be analyzed).
%
%\item If $x_j$ has a 1 in the first row of $BM$ then $x_j$ is added to $T$ ($T = T \cup \{x_j\}$), go to
%step 5; otherwise, the algorithm finishes (any new feature combination
%will not generate a typical testor, because all these combinations have a zero row).
%
%\item The new feature is added to the current combination ($T = T \cup \{x_j\}$), and it is verified whether this new feature contributes to the current combination. If the answer is negative, go to step 6.
%
%\item Verify whether $T$ is a testor, if yes, then verify whether it is a typical testor. If $T$ is a typical testor, the combination $T$ is saved in $TT$. If this is not the case, go to step 7.
%
%\item The last feature analysed $x_j$ is eliminated from $T$ ($T = T \setminus \{Xj\}$). If $x_j$ does not contribute
%to $T$, then no combination containing $T$ is verified (proposition \ref{prop1}). Go to step 7. If the
% combination was a testor, then no consecutive superset of the current combination is analysed 
% (proposition \ref{prop2}). If $T = \emptyset$ then $j = j + 1$, go to step 3.
% 
%\item The next non-analysed feature in the current combination is selected. If $j < n$ then $j = j + 1$, 
%and go to step 4; otherwise, go to step 6.
%\end{enumerate}


Example. Let us consider the basic matrix of Table~\ref{table1}, with $m=3$ rows and $n=5$ attributes. After the  ordering step we obtain the matrix shown in Table~\ref{table2}. Table~\ref{tab_example} illustrates the 
application of the CT-EXT algorithm over this basic matrix.

\begin{table}[!htb]
    \begin{minipage}{.5\linewidth}
      \caption{Basic Matrix for the example.}\label{table1}
      \centering
        \begin{tabular}{ ccccc }
 			\hline                       
  			$x_0$ & $x_1$ & $x_2$ & $x_3$ & $x_4$ \\
  			\hline
  			1 & 0 & 0 & 1 & 1 \\
  			0 & 1 & 1 & 0 & 1 \\
  			1 & 1 & 0 & 0 & 1 \\
  			\hline  
		\end{tabular}
    \end{minipage}%
    \begin{minipage}{.5\linewidth}
      \centering
        \caption{Ordered Basic Matrix obtained from the matrix of Table~\ref{table1}.}\label{table2}
        \begin{tabular}{ ccccc }
 			\hline                       
  			$x_0$ & $x_3$ & $x_4$ & $x_1$ & $x_2$ \\
  			\hline
  			1 & 1 & 1 & 0 & 0 \\
  			0 & 0 & 1 & 1 & 1 \\
  			1 & 0 & 1 & 1 & 0 \\
  			\hline  
		\end{tabular}
    \end{minipage} 
\end{table}

\newcommand{\lcell}[2][2in]{$\vcenter{\hsize#1\baselineskip11pt\vspace*{2.5pt}\raggedright#2\strut}$}

      %\centering
        \begin{longtable}{cccccl}
		\caption[CT-EXT example.]{CT-EXT algorithm example.} \label{tab_example} \\
 			\hline                       
  			\multicolumn{1}{>{\centering\arraybackslash}m{.12in}}{$T$} & 
  			\multicolumn{1}{>{\centering\arraybackslash}m{.5in}}{\scriptsize{Evaluate $(BM,T)$}} &
  			\multicolumn{1}{>{\centering\arraybackslash}m{.15in}}{$x_j$} & 
  			\multicolumn{1}{>{\centering\arraybackslash}m{.6in}}{\scriptsize{$T\cup\{x_j\}$}} &
  			\multicolumn{1}{>{\centering\arraybackslash}m{.8in}}{\scriptsize{Evaluate $(BM,T\cup\{x_j\})$}} & 
  			\multicolumn{1}{>{\centering\arraybackslash}m{1in}}{Comments}\\
  			\hline
  			$\{~\}$ & F, F, $\infty$ & $x_0$ & $\{x_0\}$ & F, F, 1 & 
  			\scriptsize{\lcell{$\{x_0\}$ is not a testor. Add a new attribute.}}\\
  			$\{x_0\}$ & F, F, 1 & $x_3$ & $\{x_0,x_3\}$ & F, F, 1 &
  			\scriptsize{\lcell{$x_3$ does not contribute. Eliminate $x_3$. Add a new attribute.}}\\
  			$\{x_0\}$ & F, F, 1 & $x_4$ & $\{x_0,x_4\}$ & T, F, 0 &
  			\scriptsize{\lcell{$x_4$ contributes, $\{x_0,x_4\}$ is testor but is not irreducible.
  			 	Eliminate $x_4$. Add a new attribute.}}\\
  			$\{x_0\}$ & F, F, 1 & $x_1$ & $\{x_0,x_1\}$ & T, T, 0 &
  			\scriptsize{\lcell{$x_1$ contributes, $\{x_0,x_1\}$ is an irreducible testor.
  				It is saved ($TT = \{\{x_0,x_1\}\}$).
  			 	Eliminate $x_1$. Add a new attribute.}}\\
  			$\{x_0\}$ & F, F, 1 & $x_2$ & $\{x_0,x_2\}$ & T, T, 0 &
  			\scriptsize{\lcell{$x_2$ contributes, $\{x_0,x_2\}$ is an irreducible testor.
  				It is saved ($TT = \{\{x_0,x_1\},\{x_0,x_2\}\}$).
  			 	Eliminate $x_2$. Add a new attribute.}}\\
  			$\{x_0\}$ & \multicolumn{5}{>{\centering\arraybackslash}m{5in}}{All attributes tested. 
  			Eliminate $x_0$ and add a new one.}\\
  			\hline 
  			$\{~\}$ & F, F, $\infty$ & $x_3$ & $\{x_3\}$ & F, F, 2 & 
  			\scriptsize{\lcell{$\{x_3\}$ is not a testor. Add a new attribute.}}\\
  			$\{x_3\}$ & F, F, 2 & $x_4$ & $\{x_3,x_4\}$ & T, F, 0 &
  			\scriptsize{\lcell{$x_4$ contributes, $\{x_3,x_4\}$ is testor but is not irreducible.
  			 	Eliminate $x_4$. Add a new attribute.}}\\
  			$\{x_3\}$ & F, F, 2 & $x_1$ & $\{x_3,x_1\}$ & T, T, 0 &
  			\scriptsize{\lcell{$x_1$ contributes, $\{x_3,x_1\}$ is an irreducible testor.
  				It is saved ($TT = \{\{x_0,x_1\},\{x_0,x_2\},\{x_3,x_1\}\}$).
  			 	Eliminate $x_1$. Add a new attribute.}}\\
  			$\{x_3\}$ & F, F, 2 & $x_2$ & $\{x_3,x_2\}$ & F, F, 1 & 
  			\scriptsize{\lcell{$x_2$ contributes but $\{x_3,x_2\}$ is not a testor. Add a new attribute.}}\\
  			$\{x_3\}$ & \multicolumn{5}{>{\centering\arraybackslash}m{5in}}{All attributes tested. 
  			Eliminate $x_3$ and add a new one.}\\
  			\hline 
  			$\{~\}$ & F, F, $\infty$ & $x_4$ & $\{x_4\}$ & T, T, 0 & 
  			\scriptsize{\lcell{$\{x_4\}$ is an irreducible testor.
  				It is saved ($TT = \{\{x_0,x_1\},\{x_0,x_2\},\{x_3,x_1\},\{x_4\}\}$).
  			 	Eliminate $x_4$. Add a new attribute.}}\\
  			\hline  
  			$\{~\}$ & F, F, $\infty$ &  $\{x_1\}$ & \multicolumn{3}{>{\centering\arraybackslash}m{4in}}{
  			$x_1$ has a 0 in first row of $BM$, Algorithm finishes.}\\
  			\hline  
		\end{longtable}

\section{Proposed platform}
\label{sect:3}

Since algorithms for computing all irreducible testors have
exponential complexity regarding the number of attributes, 
software based implementations may take an unacceptable amount of time. 
A common stage to all algorithms for computing irreducible testors is 
the verification of each candidate combination over the basic matrix. 
This is an intrinsic parallel operation that hardware implementation 
could take advantage of.
Our platform consists in the implementation of a
hardware architecture for computing all irreducible testors based on
the CT-EXT algorithm. 

The proposed platform is shown in Fig.\,\ref{figArq}. The platform comprises a host PC and 
an FPGA-based board \citep{R15}; which are connected through an USB cable. Software component, 
running  in the PC, handles the interaction with the user and the FPGA configuration. The 
hardware component, on the other hand, carries out the main calculations.
A detailed description of all platform components is given below.

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=13cm]{Arquitecture.eps}
    \end{center}
\caption{Proposed hardware-software platform.}
\label{figArq}
\end{figure}

\subsection{Hardware architecture}
\label{sect:4}

\begin{figure}[htb]
    \begin{center}
        \includegraphics[width=13cm]{CT-ext_arq.eps}
    \end{center}
\caption{CT-EXT Architecture.}
\label{fig:3}
\end{figure}

In the hardware platform, a feature subset is handled as an $n$-tuple, using a positional 
representation for all the $n$ attributes of a basic matrix $BM$. Given a subset $T$, its $n$-tuple representation 
has a 1 in the corresponding position $j$ for each $x_j \in T$ and 0 otherwise.
The process of deciding whether an $n$-tuple is a testor of $BM$ involves
comparing the candidate against each one of the $BM$'s rows. For
software-only implementations, this is a big disadvantage, specially for large 
matrices with many rows. The proposed hardware architecture exploits the parallelism 
inherent in the CT-EXT algorithm
and evaluates whether a candidate is an irreducible testor, or not, in a single
clock cycle. The hardware implementation of CT-EXT is composed of two modules as seen in
Fig.\,\ref{fig:3}. 

The $BM$ module stores the input matrix and
includes logic to decide whether an $n$-tuple is a testor. The candidate
generator module produces the candidates ($n$-tuples) to be
evaluated by the $BM$ module. In order to calculate the next candidate
according to the CT-EXT algorithm, the architecture feedbacks the
evaluation result of the previous candidate to the generator module;
this drastically reduces the number of candidates tested and
consequently the number of iterations needed by the algorithm. 
%At this
%point, the architecture is able to obtain all testors of $BM$,
%however since only irreducible testors are of interest, a final
%hardware processing module eliminates most of the testors that are
%not irreducible before sending the remaining testors to the software
%for final processing. The dismiss module exploits the way
%consecutive testors are obtained. If a testor is a superset of at
%least one previous testor, it is not an irreducible testor, thus it
%is eliminated. This final process does not introduce delays, thus
%the architecture is still capable of evaluating a candidate in a
%single clock cycle.

\begin{figure}[htb]
    \begin{center}
        \includegraphics[height=6cm]{BM_module.eps}
    \end{center}
\caption{$BM$ module.}
\label{fig:4}
\end{figure}

The $BM$ module is composed of $M$ sub-modules named \textit{row~i}, as shown
in Fig.\,\ref{fig:4}. Each \textit{row~i} module contains a row ($n$ bits)
of the $BM$ matrix and the logic needed to perform testor evaluation. To decide
whether an $n$-tuple is a testor, a bitwise AND operation is performed
between the constant stored in each \textit{row~i} module and the current
candidate, as shown in Fig.\,\ref{fig:row}. If at least one bit of the AND operation is TRUE,
then the output \textit{Testor} of that particular \textit{row~i} sub-module
will be TRUE. The same operation is performed over the previous candidate.
If the output \textit{Testor} is different from
the output \textit{Contributes} for any \textit{row~i} sub-module, 
then the output \textit{Contributes} from the $BM$ module becomes TRUE.
If the output $Testor$ of all  \textit{row~i} sub-modules is
TRUE, then the output \textit{Testor} of the $BM$ module will be TRUE,
which means that the candidate is a testor of $BM$.

\begin{figure}[htb]
    \begin{center}
        \includegraphics[height=6cm]{BM_row.eps}
    \end{center}
\caption{$BM$ row.}
\label{fig:row}
\end{figure}

% Support for the use of ANDed in other papers
% A fully bypassed six-issue integer datapath and register file on the itanium-2 microprocessor
% Implementing associative search and responder resolution
In order to verify the irreducible condition, an \textit{N~to~N~Decoder}
receives as input the result of the AND operation between the current candidate and the corresponding $BM$ row.
The output from the \textit{N~to~N~Decoder} repeats the input when there is only one bit set
to 1, and returns zero otherwise. For those rows with only one bit having a 1 after ANDed with the candidate,
the attribute in the position of that bit is indispensable if the candidate is a testor.
According to definition~\ref{def24}, every attribute in a testor must be indispensable to be an
irreducible testor. %This idea is stated in definition~1 of \citep{R13}.

\setlength{\tabcolsep}{3pt}
\begin{table}[!htb]
    \begin{minipage}{.5\linewidth}
      \caption{An example of irreducible testor.}\label{table4}
      \centering
        \begin{tabular}{ ccccc|ccccc }
 			\hline                       
  			\multicolumn{5}{c|}{Cand. $\{x_0, x_1\}$} & 
  			\multicolumn{5}{c}{Decoder output} \\
  			\hline
			  $x_0$ &   $x_3$ &   $x_4$ &   $x_1$ &   $x_2$ &
  			  $x_0$ &   $x_3$ &   $x_4$ &   $x_1$ &   $x_2$ \\
  			\hline
  			1 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\
  			0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0\\
  			1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
  			\hline  
  			\multicolumn{5}{c|}{Candidate $=$} & 1 & 0 & 0 & 1 & 0\\
  			\hline  
		\end{tabular}
	%\end{table}
	%\begin{table}[!htb]
    \end{minipage}%
    \begin{minipage}{.5\linewidth}
      \centering
        \caption{An example of not irreducible testor.}\label{table5}
        \begin{tabular}{ ccccc|ccccc }
 			\hline                       
  			\multicolumn{5}{c|}{Cand. $\{x_0, x_4\}$} & 
  			\multicolumn{5}{c}{Decoder output} \\
  			\hline
  			%\multicolumn{5}{c|}{$x_0~x_3~x_4~x_1~x_2$}&\multicolumn{5}{c}{$x_0~x_3~x_4~x_1~x_2$}\\
  			  $x_0$ &   $x_3$ &   $x_4$ &   $x_1$ &   $x_2$ &
  			  $x_0$ &   $x_3$ &   $x_4$ &   $x_1$ &   $x_2$ \\
  			\hline
  			1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  			0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
  			1 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  			\hline  
  			\multicolumn{5}{c|}{Candidate $\neq$} & 0 & 0 & 1 & 0 & 0\\
  			\hline  
		\end{tabular}
    \end{minipage} 
\end{table}

Taking as example the ordered basic matrix of Table~\ref{table2}. In Table~\ref{table4} the irreducibility of  $\{x_0,x_1\}$ is evaluated while the same is done for $\{x_0,x_4\}$ in Table~\ref{table5}. Left rows show the result of the AND operation between each row of $BM$ and the candidate, while those rows in the right show the decoder output taking as input its corresponding left row. In the last row, the result of an OR operation over all above bits is shown. According to our previous explanation, the candidate $\{x_0,x_1\}$ is an irreducible testor given that the result of the OR operation is equal to the candidate itself; while candidate $\{x_0,x_4\}$ is not. This can be corroborated in Table~\ref{tab_example}.

\begin{figure}[t]
    \begin{center}
        \includegraphics[height=6cm]{CandGen.eps}
    \end{center}
\caption{Candidate Generator module.}
\label{fig:5}
\end{figure}

The candidate generator module (Fig.\,\ref{fig:5}) uses the feedback from the $BM$ module
to calculate the next candidate to be evaluated. The
candidate generator module consists of three
registers for holding the current candidate (\textit{$Curr\_cand$}), the previous candidate
(\textit{$Prev\_cand$}) and the last added attribute ($J$). These registers values are updated
by the modules EA1, EA2 and A.

Depending on the combination of the input values, the outputs E1A,
E2A or A are used for updating the records. Table~\ref{tab_CandGen} shows how the records are updated 
according to the values of \textit{Testor}, \textit{Contributes} and $J$ inputs. 
This operation is computed by the module \textit{sel} shown in Fig.\,\ref{fig:5}.

 \begin{table}[htb]
		\caption{Candidate Generator Selector.} \label{tab_CandGen}
		\centering
 	\begin{tabular}{ccc}
 			\hline
 			Priority & Condition & Registers update\\
 			\hline
 			1 & \multicolumn{1}{>{\centering\arraybackslash}m{1in}}{$J=J_{max}$
 				($J_{max}=$ max value of $J$)} & \multicolumn{1}{>{\centering\arraybackslash}m{2in}}{
 				$Curr\_cand$ $\leftarrow$ E2A
 				$Prev\_cand$~$\leftarrow$~E2A
 				$J$~$\leftarrow$~E2A}\\
 			\hline
 			2 & \multicolumn{1}{>{\centering\arraybackslash}m{1.2in}}{Contributes $=0$ or Testor $=1$} &
 			\multicolumn{1}{>{\centering\arraybackslash}m{2in}}{
 				$Curr\_cand$ $\leftarrow$ E1A
 				$Prev\_cand$~$\leftarrow$~E1A
 				$J$~$\leftarrow$~E1A}\\
 			\hline
 			3 & \multicolumn{1}{>{\centering\arraybackslash}m{1.2in}}{Contributes $=1$ or Testor $=0$}&
 			\multicolumn{1}{>{\centering\arraybackslash}m{2in}}{
 				$Curr\_cand$ $\leftarrow$ A
 				$Prev\_cand$~$\leftarrow$~$Curr\_cand$
 				$J$~$\leftarrow$~A}\\
 			\hline       
 	\end{tabular}             
 \end{table}

The submodule $A$, shown in Fig.\,\ref{fig:subA}, assigns 1 to the next attribute at the right of 
the last bit with value 1 in the input candidate. The outputs of the submodule $A$ are the new candidate 
and $J+1$.

The submodule $E1A$, shown in Fig.\,\ref{fig:subEA1}, comprises the \textit{Rem$\_1$} 
(Fig.\,\ref{fig:subRem1}) and $A$ submodules. 
The submodule \textit{Rem$\_1$} deletes the last attribute added to the input candidate. 
This action is performed by a priority encoder which locates the last bit with value 1 in the input candidate. 
\textit{Rem$\_1$} outputs represent the previous candidate and the index of the deleted bit. 
%: $J$ and \textit{candidate} which is the input candidate without the last attribute. 
These outputs are connected to the corresponding inputs of the
submodule $A$, in order to add an attribute in the corresponding position. Finally, the outputs of $E1A$ 
represent the new candidate to be evaluated, the previous candidate and the index where the new attribute 
was added to the current candidate.

\begin{figure}[htb]
\centering
\begin{minipage}{.5\textwidth}
  \centering
   \includegraphics[width=.7\linewidth , height=3cm]{Add1.eps}
  \caption{Submodule A.}
  \label{fig:subA}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
   \includegraphics[width=\linewidth , height=3cm]{EA1.eps}
  \caption{Submodule E1A.}
  \label{fig:subEA1}
\end{minipage}
\end{figure}

Finally, the submodule $E2A$ removes the last two attributes from the
input candidate, and then adds the following corresponding attribute. This 
operation is performed by means of two \textit{Rem$\_1$} submodules and an $A$ submodule, as 
shown in Fig.\,\ref{fig:subEA2}.

In order to check if the execution of the CT-EXT  algorithm has finished, the result of an AND 
operation between the current candidate and the first row of the basic matrix is compared to 
the null $n$-tuple ($0,...,0$), as shown in the upper right corner of Fig.\,\ref{fig:5}. If the 
result of this comparison is TRUE, then the output $done$ is activated because any further 
candidate will not satisfy the testor condition over the first row of $BM$ 
(line~\ref{row1condition} of algorithm~\ref{ctext_algo}).

\begin{figure}[htb]
\centering
\begin{minipage}{.5\textwidth}
  \centering
   \includegraphics[width=\linewidth , height=3cm]{Rem1.eps}
  \caption{Submodule $Rem\_1$.}
  \label{fig:subRem1}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
   \includegraphics[width=\linewidth , height=3cm]{EA2.eps}
  \caption{Submodule E2A.}
  \label{fig:subEA2}
\end{minipage}
\end{figure}

\subsubsection*{The FPGA-based board}
The Atlys board from Digilent \citep{R15} was selected as the prototyping board. This board is 
a development platform based on a Xilinx Spartan-6 LX45 FPGA, speed grade -3. The Atlys board 
supports device programming and simplified user-data transfer at a maximum rate of 48MB/s, over 
a single USB connection. 

The communication between the host PC and the FPGA uses the Digilent Synchronous 
Parallel Interface (DSTM) protocol \citep{R25}. Irreducible testors $n$-tuples, computed by the 
proposed architecture, are buffered within a FIFO in order to be split into bytes. These bytes 
are then buffered into a double clocked FIFO \citep{R26} to be read from the PC. This last FIFO 
ensures the output interface operation at 48MHz, as required by the DSTM protocol.

\subsection{Software Description}
\label{sect:5}

The software component allows the user to provide the basic matrix in a 
plain text file following the format shown in Fig.\,\ref{fig:8}. The software component is responsible for 
programming the FPGA device and communicating with the board during irreducible testor computation.

First, the basic matrix is reorganized by setting one of the rows with the minimum amount of ones as the 
first row and swapping columns in such a way those with a 1 in the first row appear on the left. 

Using the sorted basic matrix, a VHDL file is generated and the synthesis and optimization process is started.
This way, the optimization stage takes advantage of the basic matrix data to minimize the FPGA resource 
utilization. Then, the programming file for the FPGA device is generated.

On the running stage, the software component interacts with the hardware architecture. 
First, the device is programmed with the bit-file obtained from the previous stage. Then, the
hardware architecture starts computing irreducible testors. 
The software component keeps pulling through a USB port for new irreducible testors in the output 
FIFO until the $done$ signal is activated in the FPGA.

As a result of the sorting process, the order of attributes in the basic matrix is altered as can 
be seen comparing Tables~\ref{table1} and~\ref{table2}. Consequently, the irreducible testors calculated 
in the FPGA must be codified according to the order of columns in the original basic matrix. This task 
is performed by the software component and then the results are written to the output file.

\begin{figure}[t]
    \begin{center}
        \includegraphics[height=2.8cm]{infile.eps}
    \end{center}
\caption{Input file format.}
\label{fig:8}
\end{figure}

\section{Evaluation and Discussion}
\label{sect:6}


In order to show the performance of the proposed platform, it was compared against a software 
implementation of the CT-EXT algorithm and the BT hardware platform previously reported in \citep{R21}. 
For experimentation purposes, the BT hardware platform was modified for finding irreducible testors 
on the FPGA as we did for CT-EXT. This modification avoids the final filtering stage 
proposed by \cite{R21}.

In order to understand the design of our experiments, first some important points about algorithms and 
implementations are commented. 
Either CT-EXT or BT (modified) hardware implementations are capable of evaluating a candidate per clock 
cycle. If both architectures are running at the same frequency, as it will be the case in our experiments, 
there are two reasons for differences in running time. The first one is the time taken for reorganization 
of basic matrix, which is a more complex process in BT, but it can be neglected as shown in \citep{R21}. 
The second and the most relevant, is the amount of candidates to be evaluated. 
%It is not a difficult task to find a $BM$ in which BT evaluates less candidates than CT-EXT or vice versa.

Regarding to the software implementation, the CT-EXT hardware platform has two disadvantages. First, 
VHDL code is generated for each $BM$ data and a process of synthesis must be executed previously to 
executing the algorithm; while this is unnecessary in the software version of CT-EXT. Secondly, the 
software will be running in a PC at a frequency of 3.10GHz while FPGA architecture will run at 50MHz. 

These disadvantages make the hardware approach useful (faster) under two conditions. First, the number of 
candidates to be evaluated is big enough to overcome the synthesis overhead. Second, the dimensions of the 
$BM$ are big enough to provide a considerable speed up of the candidate evaluation process. Although 
the hardware architecture could be designed for a fixed maximum matrix size and receive the $BM$ through the 
USB port, by doing this, the size of the problem which can be solved would be significantly reduced. The 
synthesis process comprehend an optimization of the design, taking advantage of the $BM$ data distribution for 
the reduction of the generated hardware configuration. The number of operations for the evaluation of a single 
candidate, in the software approach, is proportional to the number of rows and it is directly related to the 
number of columns in the $BM$. This way we can have an advantage, even at a much lower running frequency, from 
evaluating a candidate every clock cycle.

With these points in mind, in order to show the usability of the proposed platform, 
three kinds of basic matrices were randomly generated. Each type containing different percentage of 1's: 
\begin{enumerate}
	\item Very-low density matrices: approximately 8\%.
	\item Low density matrices: approximately 33\%.
	\item Medium density matrices: approximately 45\%.
\end{enumerate}

Higher density matrices were discarded because they do not constitute a computationally expensive problem, 
as stated by \cite{R21}. Here after, we will be referring to these three sets of matrices by its 
density of~1's.

\begin{figure}[htb]
\centering
\begin{minipage}{.5\textwidth}
  \centering
   \includegraphics[width=\linewidth , height=5.5cm]{low_density.eps}
  \caption{Total runtime for density 8\%.}
  \label{fig:result1}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
   \includegraphics[width=\linewidth , height=5.5cm]{med_density.eps}
  \caption{Total runtime for density 33\%.}
  \label{fig:result2}
\end{minipage}
\end{figure}

\begin{figure}[htb]
    \begin{center}
        \includegraphics[height=5.5cm]{med48_density.eps}
    \end{center}
\caption{Total runtime for density 45\%.}
\label{fig:result3}
\end{figure}

For our experiments, basic matrices of different sizes were randomly generated, for the three types. For the
hardware platforms, we measure the runtimes including the time for the following stages: $BM$ input parsing 
and VHDL code generation, synthesis process, and irreducible testor computation (with the hardware 
component running at 50MHz). The number of rows for each type of matrices is conditioned by the dimensions of 
the biggest matrix that may be synthesized at the desired running frequency.

All experiments are performed using an Intel(R) Core(TM) i5-2400 CPU @ 3.10GHz for software executions and 
an Atlys board, powered by a Spartan-6 LX45 FPGA device, for the hardware components.
Figs.\,\ref{fig:result1}, \,\ref{fig:result2}, and \,\ref{fig:result3} show graphs of the runtime (in hours) 
for the three kind of basic matrices. 

The proposed CT-EXT hardware platform (CTH) results were taken as reference for axis limits in 
Figs.\,\ref{fig:result1}, \,\ref{fig:result2}, and \,\ref{fig:result3}.
Slowest executions of the CT-EXT software implementation (CTS) are not shown in order to keep clarity in 
the figures. 
The hardware platform for BT (BTH) was not able to met the constrain of 50MHz clock frequency for some 
matrices. In fact, for medium  density, BT platform could not be synthesized even for the smaller matrix. 
%TODO Tal vez en estos casos se debería sintetizar a menor frecuencia y mostrar estos tiempos como referencia
This is the case for all missing BTH executions in Figs.\,\ref{fig:result1}, \,\ref{fig:result2}, and \,\ref{fig:result3}.
%It is important to notice that this modified architecture of the BT algorithm uses considerably more 
%FPGA resources than the original one proposed in \citep{R21}.

\cite{R21} stated that the time for computing irreducible testors does not only depend on the size and 
density of the $BM$, but also on the distribution of 0's and 1's inside the matrix. This assertion can 
be also confirmed from matrices with 68 and 70 attributes respectively, in Fig.\,\ref{fig:result3}.

Table~\ref{table:8} shows the runtime for each stage of the data flow, for 
400x40, 400x42 and 400x44 very-low density matrices. This table shows that the synthesis time 
becomes less significative regarding the total time when the problem size increases. 
From this table, it can also be seen that the main difference between the BT and CT-EXT hardware 
implementations is the runtime of the irreducible testor computation process. The main reason for 
this difference is the number of candidates evaluated by each algorithm. This is an explanation 
about why the BT hardware implementation is slower than the software version of CT-EXT for the 
largest matrix in Table~\ref{table:8}.


\begin{table}[htb]
\caption{Processing time in seconds (broken down for each stage) for 
400x40, 400x42 and 400x44 very-low density matrices.} \label{table:8}
\begin{center}
    \begin{tabular}{lcccccc}   \hline
    	   Dimensions                & \multicolumn{2}{c}{400x40} & \multicolumn{2}{c}{400x42} 
    	                             & \multicolumn{2}{c}{400x44} \\ \hline
    	    	Stage	        			& CTH & BTH	& CTH & BTH & CTH & BTH \\ \hline
    	    Load and file generation & 0.05& 0.07& 0.05& 0.06& 0.06& 0.06\\
    	    Synthesis process        & 253 & 656 & 401 & 564 & 452 & 612\\
    	    Algorithm execution      & 300 & 1071& 970 & 3826& 2031& 13311\\ \hline
    	    Total time               & 554 & 1727& 1372& 4390& 2484& 13924\\ \hline
    	    CTS total time               & \multicolumn{2}{c}{3238} & \multicolumn{2}{c}{7320} 
    	    								& \multicolumn{2}{c}{12420}\\ \hline
    	    
    \end{tabular}
\end{center}
\end{table}

Tables~\ref{table:6} and~\ref{table:7} summarize the FPGA resource utilization on our prototyping board. 
The maximum operation frequency from Tables~\ref{table:6} and~\ref{table:7} shows that usually the CT-EXT 
implementation is potentially faster than the modified BT implementation. Resource utilization is 
directly related to $BM$ dimensions, its density and to a lesser extent to data organization.

\begin{table}[htb]
\caption{Synthesis summary of resource utilization for $BM$ with 8\% density on an Spartan-6 LX45 
FPGA device.} \label{table:6}
\begin{center}
    \begin{tabular}{lcccc}   \hline
    	    Dimensions & \multicolumn{2}{c}{400x40} & \multicolumn{2}{c}{400x44} \\ \hline
    	    Algorithm & BT & CT-EXT & BT & CT-EXT \\ \hline
        Slices & 1,398 (20\%) & 983 (14\%) & 1,554 (22\%) & 1,209 (17\%)  \\
        6-input LUTs & 4,010 (14\%) & 2,806 (10\%)& 4,475 (16\%)  & 3,004 (11\%)\\
        Flip-Flops & 832 (1\%) & 852 (1\%) & 876 (1\%) & 938 (1\%)\\
        Max clock freq & 80.44MHz & 179.58MHz & 84.56MHz & 173.24MHz\\ \hline
    \end{tabular}
\end{center}
\end{table}

\begin{table}[htb]
\caption{Synthesis summary of resource utilization for $BM$ with 33\% density on an Spartan-6 LX45 
FPGA device.} \label{table:7}
\begin{center}
    \begin{tabular}{lcccc}   \hline
    	    Dimensions & \multicolumn{2}{c}{225x50} & \multicolumn{2}{c}{225x55} \\ \hline
    	    Algorithm & BT & CT-EXT & BT & CT-EXT \\ \hline 
        Slices & 1,381 (20\%) & 1,554 (22\%) & 1,455 (21\%) & 1,562 (22\%) \\
        6-input LUTs & 3,769 (13\%) & 4,315 (15\%) & 4,135 (15\%) & 5,026 (18\%)\\
        Flip-Flops & 949 (1\%) & 980 (1\%) & 1,002 (1\%) & 1,039 (1\%)\\
        Max clock freq & 87.46MHz & 155.40MHz & 85.27MHz & 156.35MHz\\ \hline
    \end{tabular}
\end{center}
\end{table}

%\section{Discussion}
%\label{sect:7}

As we have shown in previous section, the proposed hardware platform provides higher processing
performance than the software implementation of the CT-EXT
algorithm for the matrices used in our experimentation. 
This behaviour is possible because the hardware
component of the proposed platform is capable of testing whether a 
candidate is a testor of a $BM$ in a single clock cycle,
independently of the number of columns and rows, whereas
the software implementation runtime will significantly
increase for matrices with a large number of rows.

%Moreover, the performance improvement is directly related to the
%number of candidates tested, which heavily depends on the
%density and distribution of the 1's into the basic matrix. 
%This occurs in the
%software as well as in the hardware implementation,
%but the proposed platform also needs to synthesize the specific
%architecture. For practical purposes, a concurrent approach can be used 
%in computation of irreducible testors. This way, the same $BM$ is provided 
%to hardware and software implementations of BT and CT-EXT algorithms at the same time. 
%We can get the answer from the faster one without knowing which will be the best 
%for the given data.

Experiment results show that the proposed platform beats the software implementation of
the CT-EXT algorithm, with rates around \textbf{one order} of magnitude. However, for large 
enough datasets this improvement could be significantly higher, as can be inferred from 
Fig.\,\ref{fig:result3}.

\section{Conclusions}
\label{sect:8}

The good performance of our hardware implementation is feasible due to the
high level of parallelism implicit in candidates evaluation of the CT-EXT algorithm which can be
efficiently implemented on an FPGA. 
The proposed platform improves the previously reported architecture \citep{R21} by finding 
\textit{irreducible} testors in a single clock cycle. This new feature solves problems arising 
from transmission of irrelevant data to the hosting PC; improving the total runtime. 

%Main drawback of proposed platform is the limitation in matrix dimensions depending on FPGA 
%device capacity. Reducing the clock frequency allows the implementation of larger matrices at the 
%cost of slower execution.

The proposed architecture offers an alternative to the hardware implementation of BT which is faster in most 
of the cases. 

Our experiments also show that the proposed platform uses fewer hardware resources and is able to run at a higher 
frequency than the BT hardware implementation, which allows processing larger matrices, since the maximum size of 
the problem that can be solved in a hardware architecture is conditioned by its resource utilization. The search for new algorithms that could be efficiently implemented in an FPGA constitutes future work. Improvements, such 
as testing two or more candidates per iteration, are still unexplored and would be evaluated in further studies.



\section*{References}
\bibliographystyle{elsarticle-harv}


%% References without bibTeX database:

\begin{thebibliography}{00}

%\bibitem[Al-ani (2009)]{R17} Al-Ani, A. (2009). A dependency-based search strategy for feature selection Expert Systems with Applications, 36, 12392-12398.
%\bibitem[Asaithambi et al. (2004)]{R6}Asaithambi, A. and Valev, A. (2004). Construction of all non-reductible descriptors. Pattern Recognition, 37, 1817-1823.
%\bibitem[Chen et al. (2008)]{R18}Chen, w. S., Tseng, S. S. and Hong, T. P. (2008). An efficient bit-based feature selection method. Expert Systems with Applications, 34, 2858-2869.
\bibitem[Compton et al.(2002)]{R29}Compton, K., and Hauck, S. (2002). Reconfigurable computing: a survey of systems and software. ACM Computing Surveys (csuR), 34(2), 171-210.
\bibitem[Cumplido et al.(2006)]{R10} Cumplido, R., Carrasco, A. and Feregrino, C. (2006). On the Design and Implementation of a High Performance Configurable Architecture for Testor Identification. Lectures Notes on Computer Science, 4225, 665-673.
\bibitem[Djukova(2005)]{R8}Djukova, E. V. (2005). On the number of irreducible coverings of an integer Matrix. Computational Mathematics and Mathematical Physics, 45, 903-908.
\bibitem[Dmitriev et al.(1966)]{R12} Dmitriev, A. N.,  Zhuravlev, Y. I. and Krendeliev, F. P. (1966). About Mathematical Principles of Objects and Phenomena Classification. Diskretni Analiz, 7, 3-17.
\bibitem[G\'omez(2001)]{R16}G\'omez, M. (2001). Hardware-in-the-Loop Simulation. Embedded Systems Programming, 14, 38-49.
\bibitem[Guyon et al.(2003)]{R4}Guyon, I. and Elisseeff, A. (2003). An introduction to variable and feature selection. Journal of Machine Learning Research, 3, 1157-1182.
\bibitem[Jain et al.(1997)]{R3}Jain, A. and Zongker, D. (1997). Feature Selection: Evaluation, Application, and Small Sample Performance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 9, 153-158.
\bibitem[Kudryavtsev(2006)]{R9}Kudryavtsev, V. B. (2006). Test recognition theory. Discrete Applied Mathematics, 16, 319-350.
%\bibitem[Kwan et al. (2002)]{R2}Kwan, N. and Choi, C. H. (2002). Input feature selection for classification problems. IEEE Transactions on Neural Networks, 13, 143-159.
\bibitem[Lazo-Cort\'es et al.(1995)]{R32}Lazo-Cort\'es, M., Ruiz-shulcloper, J. (1995). Determining the feature relevance for non-classically described objects and a new algorithm to compute typical fuzzy testors. Pattern Recognition Letters, 16(12), 1259-1265.
\bibitem[Lazo-Cort\'es et al.(2001)]{R1}Lazo-Cort\'es, M., Ruiz-shulcloper, J., and Alba-cabrera, E. (2001). An Overview of the Evolution of the Concept of Testor. Pattern Recognition, 34, 753-762.
%\bibitem[Liu et al. (1998)]{R19} Liu, H. and Setiono, R. (1998).Some issues on scalable feature selection. Expert Systems with Applications, 15, 333-339.
\bibitem[Mart\'inez-Trinidad et al.(2001)]{R5}Mart\'inez-Trinidad, J.F. and Guzm\'an-Arenas, A. (2001). The Logical Combinatorial Approach to Pattern Recognition an Overview through Selected Works. Pattern Recognition, 34, 741-751.
\bibitem[Pocek et al.(2013)]{R30}Pocek, K., Tessier, R., and DeHon, A. (2013, April). Birth and adolescence of reconfigurable computing: A survey of the first 20 years of field-programmable custom computing machines. In Highlights of the First Twenty Years of the IEEE International Symposium on Field-Programmable Custom Computing Machines (pp. 3-19).
\bibitem[Rojas et al.(2007)]{R11}Rojas, A., Cumplido, R., Carrasco-Ochoa, J. A., Feregrino, C. and Mart\'inez-Trinidad, J. f. (2007). FPGA Based Architecture for Computing Testors. Lectures Notes on Computer Science, 4881, 188-197.
\bibitem[Rojas et al.(2012)]{R21}Rojas, A., Cumplido, R., Carrasco-Ochoa, J. A., Feregrino, C. and Mart\'inez-Trinidad, J. f. (2012). Hardware-software platform for computing irreducible testors. Expert Systems with Applications, 39, 2203 - 2210.
\bibitem[Ruiz-Shulcloper et al.(1985)]{R31}Ruiz-Shulcloper, J., Aguila-Feros, L. and Bravo-Mart\'inez, A. (1985). BT and TB algorithms for computing all irreducible testors. Revista Ciencias Matem\'aticas, 2, 11-18.
\bibitem[Ruiz-Shulcloper(2008)]{R27}Ruiz-Shulcloper, J. (2008). Pattern recognition with mixed and incomplete data. Pattern Recognition and Image Analysis, 18(4), 563-576.
\bibitem[S\'anchez-D\'iaz et al.(2002)]{R13}S\'anchez-D\'iaz, G. and Lazo-Cort\'es, M. (2002). Modifying BT Algorithm for Improving its Runtimes. Revista Ciencias Matem\'aticas, 20, 129-136.
\bibitem[S\'anchez-D\'iaz et al.(2007)]{R22}S\'anchez-D\'iaz, G. and Lazo-Cort\'es, M. (2007). CT-EXT: An Algorithm for Computing Typical Testor Set. Lecture Notes in Computer Science, 4756, 506-514.
\bibitem[S\'anchez-D\'iaz et al.(2010)]{R23}S\'anchez-D\'iaz, G., Piza-Davila, I, Lazo-Cort\'es, M, 
Mora-Gonz\'alez, M and Salinas-Luna, J. (2010). A Fast Implementation of the CT-EXT Algorithm for the Testor Property Identification. Lecture Notes in Computer Science, 6438, 92-103.
\bibitem[Skowron et al.(1992)]{R40}Skowron, A and Rauszer, C. (1992). The discernibility matrices and functions in information systems. Handbook of Applications and Advances of the Rough Sets Theory, 331-362.

%\bibitem[Valev et al. (2004)]{R7}Valev, V. and Sankur, B. (2004). Generalized non-reducible descriptors. Pattern Recognition, 37, 1809-1815.
%\bibitem[Villuendas-Rey et al. (2008)]{R28}Villuendas-Rey, Y., García-Borroto, M., and Ruiz-Shulcloper, J. (2008). Selecting features and objects for mixed and incomplete data. In Progress in Pattern Recognition, Image Analysis and Applications (pp. 381-388). Springer Berlin Heidelberg.
\bibitem[Digilent(2013)]{R15}Atlys Board Reference Manual. Digilent, Inc.
\bibitem[Digilent(2010)]{R25}Digilent Synchronous Parallel Interface (DSTM) Programmer's Reference Manual. Digilent, Inc.
\bibitem[Xilinx(2012)]{R26}LogiCORE IP FIFO Generator v9.2. Xilinx Inc.


\end{thebibliography}

\end{document}